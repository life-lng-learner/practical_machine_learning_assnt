---
title: "Practical_ML_Assignment"
author: "PD"
date: "29/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Executive Summary
This project leverages the RandomForest prediction algorithm to predict how well people exercise. Data from the following source was utilized for the analysis: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. After clean, 53 variables were left in the training set which was then split into 70% training subset and 30% test subset. The random forest model resulted in 99.56% accuracy with and out of sample error of 0.44%. Prediction results of the 20 samples in the test set are provided towards the end of the report.


## Background
In this report, we try to predict how well people exercise. Data from accelerometers on the belt, forearm, arm and dumbell of 6 participants is used to build a prediction model and then test the model on 20 data sets. The 6 participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The data for this project and report can be found from the following source: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har.

## Install and load required packages
```{r}
if(!require('randomForest')){
  install.packages('randomForest', repos = "http://cran.us.r-project.org")
}

if(!require('caret')){
  install.packages('caret', repos = "http://cran.us.r-project.org")  
}

library(randomForest)
library(caret)
```


## Download and Read Training and Test Sets

In this section, we download the training and test data sets.
```{r}

#Download training set
if(!file.exists("pml-training.csv")){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="./pml-training.csv")
}

#Download test set
if(!file.exists("pml-testing.csv")){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile="./pml-testing.csv")
}

#Read training set
training_set<-read.csv("pml-training.csv",na.strings=c('','NA','#DIV/0!'))

#Read test set
test_set<-read.csv("pml-testing.csv",na.strings=c('','NA','#DIV/0!'))

dim(training_set)

dim(test_set)
```

## Clean-up training and test data sets

In this section we clean up both the training and test data sets using the following methods:  

1. Remove the first few variables that are used for identification and do not affect the prediction.  

2. Remove variables that are almost constant.  

3. Remove variables that have mostly NA values.  

```{r}

#Remove the first 7 variables that contain the id, timestamp and window information
training_set<-training_set[,-(1:7)]
test_set<-test_set[,-(1:7)]

#Remove near zero vars as these may not be useful for prediction
nearZero<-nearZeroVar(training_set)
training_set<-training_set[,-nearZero]
test_set<-test_set[,-nearZero]

#Remove variables that have na values
training_set<-training_set[,!apply(training_set,2,function(x) any(is.na(x)))]

test_set<-test_set[,!apply(test_set,2,function(x) any(is.na(x)))]

```
After cleanup, there are 19622 observations and 53 variables in the training set.


## Split the training set into training and test subsets (70-30 split)
In this section we are conducting a cross validation exercise by splitting the training set into 2 subsets: 70% of the observations for the training subset and 30% for the testing subset.
```{r}
subgroup<-createDataPartition(training_set$classe,p=0.7,list=FALSE)
training_subset<-training_set[subgroup,]
test_subset<-training_set[-subgroup,]
```


## Evaluate the accuracy of Random Forest algorithm to predict
We are going to use the random forest algorithm to build our prediction model, execute the prediction model on the test subset and then analyze the confusion matrix.
```{r}
set.seed(13737)
har.rf<-randomForest(classe~.,data=training_subset,method=class)

## Test the model on the test subset
pred = predict(har.rf,test_subset,type='class')

##Evaluate the performance of the model via a confusion matrix
cm=confusionMatrix(pred,test_subset$classe)

#Prediction vs reference table
cm$table

#Accuracy and out of sample error
cm$overall

```

Based on the confusion matrix above, the accuracy of the model is 99.56%. Hence the out of sample error is 0.44% with a 95% confidence interval of 0.29% and 0.65%.

Next we try to understand the importance of variables in the prediction model:

```{r}
important_vars<-varImp(har.rf)
important_vars[order(-important_vars$Overall),,drop=FALSE]

```
Based on the table of important variables above, top 3 variables that influence the prediction model the most are roll_belt, yaw_belt and pitch_forearm.


## Apply the model to the test data set
```{r}

predict_test=predict(har.rf,test_set,type='class')

```

Predictions for the 20 test samples are:
`r predict_test`